{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chassisml\n",
    "import pickle\n",
    "import cv2\n",
    "import torch\n",
    "import getpass\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter credentials\n",
    "Dockerhub creds and Modzy API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dockerhub_user = getpass.getpass('docker hub username')\n",
    "dockerhub_pass = getpass.getpass('docker hub password')\n",
    "modzy_api_key = getpass.getpass('modzy api key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare context dict\n",
    "Initialize anything here that should persist across inference runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "labels = pickle.load(open('./modzy/imagenet_labels.pkl','rb'))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])        \n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "# This will be passed to Chassis:\n",
    "context = {\n",
    "    \"model\": model,\n",
    "    \"labels\": labels,\n",
    "    \"transform\": transform,\n",
    "    \"device\": device\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write process function\n",
    "\n",
    "* Must take bytes and context dict as input\n",
    "* Preprocess bytes, run inference, postprocess model output, return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(input_bytes,context):\n",
    "    \n",
    "    # preprocess\n",
    "    decoded = cv2.imdecode(np.frombuffer(input_bytes, np.uint8), -1)\n",
    "    img_t = context['transform'](decoded)\n",
    "    batch_t = torch.unsqueeze(img_t, 0).to(device)\n",
    "    \n",
    "    # run inference\n",
    "    predictions = context['model'](batch_t)\n",
    "    \n",
    "    # postprocess\n",
    "    percentage = torch.nn.functional.softmax(predictions, dim=1)[0]\n",
    "\n",
    "    _, indices = torch.sort(predictions, descending=True)\n",
    "    inference_result = {\n",
    "        \"classPredictions\": [\n",
    "            {\"class\": context['labels'][idx.item()], \"score\": percentage[idx].item()}\n",
    "        for idx in indices[0][:5] ]\n",
    "    }\n",
    "\n",
    "    structured_output = {\n",
    "        \"data\": {\n",
    "            \"result\": inference_result,\n",
    "            \"explanation\": None,\n",
    "            \"drift\": None,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return structured_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Chassis Client\n",
    "We'll use this to interact with the Chassis service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chassis_client = chassisml.ChassisClient(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and test Chassis model\n",
    "* Requires `context` dict containing all variables which should be loaded once and persist across inferences\n",
    "* Requires `process_fn` defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data\": {\"result\": {\"classPredictions\": [{\"class\": \"airliner\", \"score\": 0.9193508625030518}, {\"class\": \"wing\", \"score\": 0.05414895340800285}, {\"class\": \"warplane, military plane\", \"score\": 0.010522882454097271}, {\"class\": \"aircraft carrier, carrier, flattop, attack aircraft carrier\", \"score\": 0.004400244913995266}, {\"class\": \"crane\", \"score\": 0.0019400565652176738}]}, \"explanation\": null, \"drift\": null}}\n"
     ]
    }
   ],
   "source": [
    "# create Chassis model\n",
    "chassis_model = chassis_client.create_model(context=context,process_fn=process)\n",
    "\n",
    "# test Chassis model (can pass filepath, bufferedreader, bytes, or text here):\n",
    "sample_filepath = './modzy/airplane.jpg'\n",
    "results = chassis_model.test(sample_filepath)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test environment and model within Chassis service, must pass filepath here:\n",
    "test_env_result = chassis_model.test_env(sample_filepath)\n",
    "print(test_env_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish model to Modzy\n",
    "Need to provide model name, model version, Dockerhub credentials, and required Modzy info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building image... Ok!\n"
     ]
    }
   ],
   "source": [
    "modzy_url = \"https://my.modzy.com\"\n",
    "\n",
    "response = chassis_model.publish(model_name=\"Torch Imagenet\",model_version=\"0.0.1\",\n",
    "                     registry_user=dockerhub_user,registry_pass=dockerhub_pass,\n",
    "                     modzy_sample_input_path=sample_filepath,\n",
    "                     modzy_api_key=modzy_api_key)\n",
    "\n",
    "job_id = response.get('job_id')\n",
    "final_status = chassis_client.block_until_complete(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run sample job\n",
    "Submit inference job to our newly-deploy model running on Modzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ApiObject({\n",
      "  \"data\": {\n",
      "    \"drift\": null,\n",
      "    \"explanation\": null,\n",
      "    \"result\": {\n",
      "      \"classPredictions\": [\n",
      "        {\n",
      "          \"class\": \"airliner\",\n",
      "          \"score\": 0.9193506836891174\n",
      "        },\n",
      "        {\n",
      "          \"class\": \"wing\",\n",
      "          \"score\": 0.054149046540260315\n",
      "        },\n",
      "        {\n",
      "          \"class\": \"warplane, military plane\",\n",
      "          \"score\": 0.010522911325097084\n",
      "        },\n",
      "        {\n",
      "          \"class\": \"aircraft carrier, carrier, flattop, attack aircraft carrier\",\n",
      "          \"score\": 0.004400256555527449\n",
      "        },\n",
      "        {\n",
      "          \"class\": \"crane\",\n",
      "          \"score\": 0.0019400684395805001\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from modzy import ApiClient\n",
    "\n",
    "client = ApiClient(base_url=f'{modzy_url}/api', api_key=modzy_api_key)\n",
    "\n",
    "input_name = final_status['result']['inputs'][0]['name']\n",
    "model_id = final_status['result'].get(\"model\").get(\"modelId\")\n",
    "model_version = final_status['result'].get(\"version\")\n",
    "\n",
    "inference_job = client.jobs.submit_file(model_id, model_version, {input_name: sample_filepath})\n",
    "inference_job_result = client.results.block_until_complete(inference_job, timeout=None)\n",
    "inference_job_results_json = inference_job_result.get_first_outputs()['results.json']\n",
    "print(inference_job_results_json)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95ab8d3bdd708a5b71676285742277315a30b0df1ed91c8905076616709c59d5"
  },
  "kernelspec": {
   "display_name": "chassis-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
