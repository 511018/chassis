{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mxnet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BRADLE~1\\AppData\\Local\\Temp/ipykernel_28880/4196225999.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgluon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmxnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgluon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_zoo\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mxnet'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import chassisml\n",
    "import numpy as np\n",
    "import getpass\n",
    "import json\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, nd\n",
    "from mxnet.gluon.model_zoo import vision\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter credentials\n",
    "Dockerhub creds and Modzy API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker hub username········\n",
      "docker hub password········\n",
      "modzy api key········\n"
     ]
    }
   ],
   "source": [
    "dockerhub_user = getpass.getpass('docker hub username')\n",
    "dockerhub_pass = getpass.getpass('docker hub password')\n",
    "modzy_api_key = getpass.getpass('modzy api key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = onnx.load(\"mobilenetv2-7.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.checker.check_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format sample serialized input into correct format\n",
    "tensor = onnx.TensorProto()\n",
    "with open(\"data/input_0.pb\", \"rb\") as f:\n",
    "    tensor.ParseFromString(f.read())\n",
    "array = numpy_helper.to_array(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose your preferred onnx runtime to run this pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "onnx.onnx_ml_pb2.ModelProto"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(373, 640, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.cvtColor(cv2.imread(\"airplane.jpg\"), cv2.COLOR_BGR2RGB)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = numpy_helper.from_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'onnx.backend' has no attribute 'run_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BRADLE~1\\AppData\\Local\\Temp/ipykernel_12932/1473329738.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'onnx.backend' has no attribute 'run_model'"
     ]
    }
   ],
   "source": [
    "backend.run_model(model, img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ModelProto' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BRADLE~1\\AppData\\Local\\Temp/ipykernel_12932/2034100655.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'ModelProto' object is not callable"
     ]
    }
   ],
   "source": [
    "model(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression mean accuracy score: 0.933333\n"
     ]
    }
   ],
   "source": [
    "# Import and normalize data\n",
    "X_digits, y_digits = datasets.load_digits(return_X_y=True)\n",
    "X_digits = X_digits / X_digits.max()\n",
    "\n",
    "n_samples = len(X_digits)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train = X_digits[: int(0.9 * n_samples)]\n",
    "y_train = y_digits[: int(0.9 * n_samples)]\n",
    "X_test = X_digits[int(0.9 * n_samples) :]\n",
    "y_test = y_digits[int(0.9 * n_samples) :]\n",
    "\n",
    "# Train Model\n",
    "logistic = LogisticRegression(max_iter=1000)\n",
    "print(\n",
    "    \"LogisticRegression mean accuracy score: %f\"\n",
    "    % logistic.fit(X_train, y_train).score(X_test, y_test)\n",
    ")\n",
    "\n",
    "# Save small sample input to use for testing later\n",
    "sample = X_test[:5].tolist()\n",
    "with open(\"data/digits_sample.json\", 'w') as out:\n",
    "    json.dump(sample, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare context dict\n",
    "Initialize anything here that should persist across inference runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be passed to Chassis:\n",
    "context = {\"model\": logistic}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write process function\n",
    "\n",
    "* Must take bytes and context dict as input\n",
    "* Preprocess bytes, run inference, postprocess model output, return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(input_bytes,context):\n",
    "    inputs = np.array(json.loads(input_bytes))\n",
    "    inference_results = context[\"model\"].predict(inputs)\n",
    "    structured_results = []\n",
    "    for inference_result in inference_results:\n",
    "        structured_output = {\n",
    "            \"data\": {\n",
    "                \"result\": {\"classPredictions\": [{\"class\": str(inference_result), \"score\": str(1)}]}\n",
    "            }\n",
    "        }\n",
    "        structured_results.append(structured_output)\n",
    "    return structured_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Chassis Client\n",
    "We'll use this to interact with the Chassis service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chassis_client = chassisml.ChassisClient(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and test Chassis model\n",
    "* Requires `context` dict containing all variables which should be loaded once and persist across inferences\n",
    "* Requires `process_fn` defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[{\"data\":{\"result\":{\"classPredictions\":[{\"class\":\"5\",\"score\":\"1\"}]}}},{\"data\":{\"result\":{\"classPredictions\":[{\"class\":\"2\",\"score\":\"1\"}]}}},{\"data\":{\"result\":{\"classPredictions\":[{\"class\":\"8\",\"score\":\"1\"}]}}},{\"data\":{\"result\":{\"classPredictions\":[{\"class\":\"0\",\"score\":\"1\"}]}}},{\"data\":{\"result\":{\"classPredictions\":[{\"class\":\"1\",\"score\":\"1\"}]}}}]'\n"
     ]
    }
   ],
   "source": [
    "# create Chassis model\n",
    "chassis_model = chassis_client.create_model(context=context,process_fn=process)\n",
    "\n",
    "# test Chassis model locally (can pass filepath, bufferedreader, bytes, or text here):\n",
    "sample_filepath = './data/digits_sample.json'\n",
    "results = chassis_model.test(sample_filepath)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test job... Ok!\n",
      "{'model_output': 'b\\'[{\"data\":{\"result\":{\"classPredictions\":[{\"class\":\"5\",\"score\":\"1\"}]}}},{\"data\":{\"result\":{\"classPredictions\":[{\"class\":\"2\",\"score\":\"1\"}]}}},{\"data\":{\"result\":{\"classPredictions\":[{\"class\":\"8\",\"score\":\"1\"}]}}},{\"data\":{\"result\":{\"classPredictions\":[{\"class\":\"0\",\"score\":\"1\"}]}}},{\"data\":{\"result\":{\"classPredictions\":[{\"class\":\"1\",\"score\":\"1\"}]}}}]\\'\\n'}\n"
     ]
    }
   ],
   "source": [
    "# test environment and model within Chassis service, must pass filepath here:\n",
    "\n",
    "# dry run before build\n",
    "test_env_result = chassis_model.test_env(sample_filepath)\n",
    "print(test_env_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish model to Modzy\n",
    "Need to provide model name, model version, Dockerhub credentials, and required Modzy info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting build job... Ok!\n"
     ]
    }
   ],
   "source": [
    "response = chassis_model.publish(\n",
    "    model_name=\"Sklearn Logistic Regression Digits Image Classification\",\n",
    "    model_version=\"0.0.1\",\n",
    "    registry_user=dockerhub_user,\n",
    "    registry_pass=dockerhub_pass,\n",
    "    modzy_sample_input_path=sample_filepath,\n",
    "    modzy_api_key=modzy_api_key\n",
    ")\n",
    "\n",
    "job_id = response.get('job_id')\n",
    "final_status = chassis_client.block_until_complete(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model URL: https://integration.modzy.engineering/models/kihikghkee/0.0.1\n"
     ]
    }
   ],
   "source": [
    "if chassis_client.get_job_status(job_id)[\"result\"] is not None:\n",
    "    print(\"New model URL: {}\".format(chassis_client.get_job_status(job_id)[\"result\"][\"container_url\"]))\n",
    "else:\n",
    "    print(\"Chassis job failed \\n\\n {}\".format(chassis_client.get_job_status(job_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run sample job using Modzy SDK\n",
    "Submit inference job to our newly-deploy model running on Modzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ApiObject({\n",
      "  \"data\": {\n",
      "    \"result\": {\n",
      "      \"classPredictions\": [\n",
      "        {\n",
      "          \"class\": \"5\",\n",
      "          \"score\": \"1\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}), ApiObject({\n",
      "  \"data\": {\n",
      "    \"result\": {\n",
      "      \"classPredictions\": [\n",
      "        {\n",
      "          \"class\": \"2\",\n",
      "          \"score\": \"1\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}), ApiObject({\n",
      "  \"data\": {\n",
      "    \"result\": {\n",
      "      \"classPredictions\": [\n",
      "        {\n",
      "          \"class\": \"8\",\n",
      "          \"score\": \"1\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}), ApiObject({\n",
      "  \"data\": {\n",
      "    \"result\": {\n",
      "      \"classPredictions\": [\n",
      "        {\n",
      "          \"class\": \"0\",\n",
      "          \"score\": \"1\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}), ApiObject({\n",
      "  \"data\": {\n",
      "    \"result\": {\n",
      "      \"classPredictions\": [\n",
      "        {\n",
      "          \"class\": \"1\",\n",
      "          \"score\": \"1\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "})]\n"
     ]
    }
   ],
   "source": [
    "from modzy import ApiClient\n",
    "\n",
    "client = ApiClient(base_url='https://integration.modzy.engineering/api', api_key=modzy_api_key)\n",
    "\n",
    "input_name = final_status['result']['inputs'][0]['name']\n",
    "model_id = final_status['result'].get(\"model\").get(\"modelId\")\n",
    "model_version = final_status['result'].get(\"version\")\n",
    "\n",
    "inference_job = client.jobs.submit_file(model_id, model_version, {input_name: sample_filepath})\n",
    "inference_job_result = client.results.block_until_complete(inference_job, timeout=None)\n",
    "inference_job_results_json = inference_job_result.get_first_outputs()['results.json']\n",
    "print(inference_job_results_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95ab8d3bdd708a5b71676285742277315a30b0df1ed91c8905076616709c59d5"
  },
  "kernelspec": {
   "display_name": "chassis-demo-1",
   "language": "python",
   "name": "chassis-demo-1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
