{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "outstanding-dimension",
   "metadata": {},
   "source": [
    "# Chassis.ml demo\n",
    "\n",
    "## Easily build MLflow models into {KFServing, Modzy} Docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-original",
   "metadata": {},
   "source": [
    "This demo will show you how we can train a model, define custom pre- and post-processing steps, save it in MLflow format and then build it into a container image and push it to docker hub with a single command.\n",
    "\n",
    "By easily connecting MLflow models to Docker images with a simple Python SDK for data scientists & ML engineers, Chassis is the missing link between MLflow and DevOps.\n",
    "\n",
    "This demo can be run in local using minikube and a local installation of Chassis.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* [Docker Hub](https://hub.docker.com/) account (free one is fine)\n",
    "* The browser you're reading this in :-)\n",
    "* Existing local installation of Chassis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a37fa609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chassisml\n",
    "import sklearn\n",
    "import mlflow.pyfunc\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-summary",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "This will train a sklearn model and it will be saved as a joblib file inside the `model` directory.\n",
    "\n",
    "The goal for Chassis service is to create an image that exposes this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0bd3c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model.joblib']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "data = digits.images.reshape((len(digits.images), -1))\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "clf = svm.SVC(gamma=0.001)\n",
    "\n",
    "# Split data into 50% train and 50% test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, digits.target, test_size=0.5, shuffle=False)\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "clf.fit(X_train, y_train)\n",
    "dump(clf, './model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04f23438",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Wrap your model in a pyfunc and provide auxiliary functionality through extension of the\n",
    "# mlflow PythonModel class with methods pre_process, post_process, and explain\n",
    "\n",
    "class CustomModel(mlflow.pyfunc.PythonModel):\n",
    "    _model = load('./model.joblib')\n",
    "    \n",
    "    def load_context(self, context):\n",
    "        self.model = self._model\n",
    "\n",
    "    def predict(self, context, inputs):\n",
    "        processed_inputs = self.pre_process(inputs)\n",
    "        inference_results = self.model.predict(processed_inputs)\n",
    "        return self.post_process(inference_results)\n",
    "\n",
    "    def pre_process(self, inputs):\n",
    "        return inputs / 2\n",
    "\n",
    "    def post_process(self, inference_results):\n",
    "        structured_results = []\n",
    "        for inference_result in inference_results:\n",
    "            inference_result = {\n",
    "                \"classPredictions\": [\n",
    "                    {\"class\": str(inference_result), \"score\": str(1)}\n",
    "                ]\n",
    "            }\n",
    "            structured_output = {\n",
    "                \"data\": {\n",
    "                    \"result\": inference_result,\n",
    "                    \"explanation\": None,\n",
    "                    \"drift\": None,\n",
    "                }\n",
    "            }\n",
    "            structured_results.append(structured_output)\n",
    "        return structured_results\n",
    "\n",
    "    def explain(self, images):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d3f74bf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define conda environment with all required dependencies for your model\n",
    "\n",
    "conda_env = {\n",
    "    \"channels\": [\"defaults\", \"conda-forge\", \"pytorch\"],\n",
    "    \"dependencies\": [\n",
    "        \"python=3.8.5\",\n",
    "        \"pytorch\",\n",
    "        \"torchvision\",\n",
    "        \"pip\",\n",
    "        {\n",
    "            \"pip\": [\n",
    "                \"mlflow\",\n",
    "                \"lime\",\n",
    "                \"sklearn\"\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    "    \"name\": \"linear_env\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144cda6c",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "Transform the model into MLFlow format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abedf16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf mlflow_custom_pyfunc_svm\n",
    "model_save_path = \"mlflow_custom_pyfunc_svm\"\n",
    "mlflow.pyfunc.save_model(path=model_save_path, python_model=CustomModel(), conda_env=conda_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c819be5",
   "metadata": {},
   "source": [
    "Load the MLFlow model and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac440385",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": {\n",
      "        \"result\": {\n",
      "            \"classPredictions\": [\n",
      "                {\n",
      "                    \"class\": \"8\",\n",
      "                    \"score\": \"1\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"explanation\": null,\n",
      "        \"drift\": null\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "classifier = mlflow.pyfunc.load_model(model_save_path)\n",
    "predictions = classifier.predict(X_test)\n",
    "print(json.dumps(predictions[0], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-northern",
   "metadata": {},
   "source": [
    "We check that the model has been correctly saved inside the `model` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "751ac7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conda.yaml  MLmodel  python_model.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./mlflow_custom_pyfunc_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-brazil",
   "metadata": {},
   "source": [
    "### Get Docker Hub credentials securely\n",
    "\n",
    "Now we prompt the user (you!) for your docker hub username and password in such a way that the value itself doesn't get written into the notebook, which is sensible security best-practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e17d7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker hub username········\n",
      "docker hub password········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import base64\n",
    "username = getpass.getpass(\"docker hub username\")\n",
    "password = getpass.getpass(\"docker hub password\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968d9ac1",
   "metadata": {},
   "source": [
    "Now we can construct the metadata that the chassis service needs to build and publish the container to docker hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ade0ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = {\n",
    "    'name': f'{username}/chassisml-sklearn-demo:latest',\n",
    "    'version': '0.0.1',\n",
    "    'model_name': 'digits',\n",
    "    'model_path': './mlflow_custom_pyfunc_svm',\n",
    "    'registry_auth': base64.b64encode(f\"{username}:{password}\".encode(\"utf-8\")).decode(\"utf-8\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf4f65ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "modzy_data = {\n",
    "    'metadata_path': './modzy/model.yaml'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f93dca3",
   "metadata": {},
   "source": [
    "### Forward ports to access service and registry\n",
    "\n",
    "This assumes that you are running these commands on your own terminal to redirect the service (port 5000) and the registry (port 5001) to localhost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cca5df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! # kubectl port-forward service/chassis 5000:5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-failing",
   "metadata": {},
   "source": [
    "### Launch the job\n",
    "\n",
    "Important fields that we should fill in here are:\n",
    "\n",
    "* `module`: library that has been used to create the model\n",
    "* `image_data`: the values defined above\n",
    "* `image_type`: this is needed in case we are training images so afterwards the proxy will know how to interpret data\n",
    "* `base_url`: the name of the service that runs Chassis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "381c6360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publishing container... Ok!\n",
      "Job ID: chassis-builder-job-6ade161a-1486-4b01-907b-6e36d039c0f4\n"
     ]
    }
   ],
   "source": [
    "res = chassisml.publish(\n",
    "    image_data=image_data,\n",
    "    modzy_data=modzy_data,\n",
    "    deploy=True,\n",
    "    base_url='http://localhost:5000'\n",
    ")\n",
    "\n",
    "error = res.get('error')\n",
    "job_id = res.get('job_id')\n",
    "\n",
    "if error:\n",
    "    print('Error:', error)\n",
    "else:\n",
    "    print('Job ID:', job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-arrow",
   "metadata": {},
   "source": [
    "After the request is made, Chassis launches a job that runs Kaniko and builds the docker image based on the values provided.\n",
    "\n",
    "You can get the id of the job created from the result of the request. This id can be used to ask for the status of the job.\n",
    "\n",
    "This is an example of the data that is shown when the job has not finished yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "wound-steering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'active': 1,\n",
       " 'completion_time': None,\n",
       " 'conditions': None,\n",
       " 'failed': None,\n",
       " 'start_time': 'Thu, 29 Jul 2021 17:03:44 GMT',\n",
       " 'succeeded': None}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chassisml.get_job_status(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec5423f",
   "metadata": {},
   "source": [
    "And this is an example of the data that is shown when the job has already finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd5d572b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'active': None,\n",
       " 'completion_time': 'Thu, 29 Jul 2021 17:15:56 GMT',\n",
       " 'conditions': [{'last_probe_time': 'Thu, 29 Jul 2021 17:15:56 GMT',\n",
       "   'last_transition_time': 'Thu, 29 Jul 2021 17:15:56 GMT',\n",
       "   'message': None,\n",
       "   'reason': None,\n",
       "   'status': 'True',\n",
       "   'type': 'Complete'}],\n",
       " 'failed': None,\n",
       " 'start_time': 'Thu, 29 Jul 2021 17:03:44 GMT',\n",
       " 'succeeded': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chassisml.get_job_status(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-prison",
   "metadata": {},
   "source": [
    "### Pull the docker image\n",
    "\n",
    "Now that the job has finished, we can pull and load the docker image that has been generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "independent-diameter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest: Pulling from carmilso/chassisml-sklearn-demo\n",
      "\n",
      "\u001b[1B7f680f63: Pulling fs layer \n",
      "\u001b[1B53afe8a0: Pulling fs layer \n",
      "\u001b[1B7a6faf2d: Pulling fs layer \n",
      "\u001b[1Be0a6cfe3: Pulling fs layer \n",
      "\u001b[1B2e6602b3: Pulling fs layer \n",
      "\u001b[1Bbf5f9440: Pulling fs layer \n",
      "\u001b[1B14f5e83b: Pulling fs layer \n",
      "\u001b[1B5593bf23: Pulling fs layer \n",
      "\u001b[1B036cba4d: Pulling fs layer \n",
      "\u001b[1B5e8bc614: Pulling fs layer \n",
      "\u001b[1Bb5369a3a: Pull complete 492kB/2.492kBB\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[8A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[3A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KDigest: sha256:bf87318e47407dd4b84bf3df09246cf809a1721b0dec06ef7cc134422dc27450\n",
      "Status: Downloaded newer image for carmilso/chassisml-sklearn-demo:latest\n",
      "docker.io/carmilso/chassisml-sklearn-demo:latest\n"
     ]
    }
   ],
   "source": [
    "!docker pull {username}/chassisml-sklearn-demo:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ordinary-majority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                        TAG       IMAGE ID       CREATED         SIZE\r\n",
      "carmilso/chassisml-sklearn-demo   latest    56b10aa0f075   4 minutes ago   2.23GB\r\n"
     ]
    }
   ],
   "source": [
    "!docker images {username}/chassisml-sklearn-demo:latest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
