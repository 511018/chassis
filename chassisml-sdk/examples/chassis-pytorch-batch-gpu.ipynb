{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chassisml\n",
    "import pickle\n",
    "import cv2\n",
    "import torch\n",
    "import getpass\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter credentials\n",
    "Dockerhub creds and Modzy API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dockerhub_user = getpass.getpass('docker hub username')\n",
    "dockerhub_pass = getpass.getpass('docker hub password')\n",
    "modzy_api_key = getpass.getpass('modzy api key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare context dict\n",
    "Initialize anything here that should persist across inference runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "labels = pickle.load(open('./modzy/imagenet_labels.pkl','rb'))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])        \n",
    "\n",
    "# use GPU:\n",
    "device = 'cuda'\n",
    "model.to(device)\n",
    "\n",
    "# This will be passed to Chassis:\n",
    "context = {\n",
    "    \"model\": model,\n",
    "    \"labels\": labels,\n",
    "    \"transform\": transform,\n",
    "    \"device\": device\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write batch process function\n",
    "\n",
    "* Must take list[bytes] and context dict as input\n",
    "* Preprocess all inputs, run inference in batch, postprocess batch model output, return list of formatted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process(inputs,context):\n",
    "    \n",
    "    # preprocess list of inputs\n",
    "    images = []\n",
    "    for input_bytes in inputs:\n",
    "        decoded = cv2.imdecode(np.frombuffer(input_bytes, np.uint8), -1)\n",
    "        resized = cv2.resize(decoded, (224, 224)).reshape((1,224,224,3))\n",
    "        images.append(resized)\n",
    "    images_arr = np.concatenate(images)\n",
    "    batch_t = torch.stack(tuple(context['transform'](i) for i in images_arr), dim=0).to(context['device'])\n",
    "\n",
    "    # run batch inference and softmax\n",
    "    output = context['model'](batch_t)\n",
    "    probs = torch.nn.functional.softmax(output, dim=1)\n",
    "    softmax_preds = probs.detach().cpu().numpy()\n",
    "    \n",
    "    # postprocess\n",
    "    all_formatted_results = []\n",
    "    for preds in softmax_preds: \n",
    "        indices = np.argsort(preds)[::-1]\n",
    "        classes = [context['labels'][idx] for idx in indices[:5]]\n",
    "        scores = [float(preds[idx]) for idx in indices[:5]]\n",
    "        preds = [{\"class\": \"{}\".format(label), \"score\": round(float(score),3)} for label, score in zip(classes, scores)]\n",
    "        preds.sort(key = lambda x: x[\"score\"],reverse=True)\n",
    "        results = {\"classPredictions\": preds}\n",
    "        all_formatted_results.append(results)\n",
    "    \n",
    "    # output list of formatted results\n",
    "    return all_formatted_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Chassis Client\n",
    "We'll use this to interact with the Chassis service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chassis_client = chassisml.ChassisClient(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and test Chassis model\n",
    "* Requires `context` dict containing all variables which should be loaded once and persist across inferences\n",
    "* Requires at least one of single input `process_fn` or batch input `batch_process_fn` defined above\n",
    "    * If you provide `batch_process_fn`, you must also provide a `batch_size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"classPredictions\":[{\"class\":\"airliner\",\"score\":0.606},{\"class\":\"crane\",\"score\":0.11},{\"class\":\"wing\",\"score\":0.103},{\"class\":\"chain saw, chainsaw\",\"score\":0.07},{\"class\":\"aircraft carrier, carrier, flattop, attack aircraft carrier\",\"score\":0.048}]}'\n"
     ]
    }
   ],
   "source": [
    "# create Chassis model\n",
    "chassis_model = chassis_client.create_model(context=context,batch_process_fn=batch_process,batch_size=4)\n",
    "\n",
    "# test Chassis model (can pass filepath, bufferedreader, bytes, or text here):\n",
    "sample_filepath = './modzy/airplane.jpg'\n",
    "results = chassis_model.test(sample_filepath)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'{\"classPredictions\":[{\"class\":\"airliner\",\"score\":0.606},{\"class\":\"crane\",\"score\":0.11},{\"class\":\"wing\",\"score\":0.103},{\"class\":\"chain saw, chainsaw\",\"score\":0.07},{\"class\":\"aircraft carrier, carrier, flattop, attack aircraft carrier\",\"score\":0.048}]}', b'{\"classPredictions\":[{\"class\":\"airliner\",\"score\":0.606},{\"class\":\"crane\",\"score\":0.11},{\"class\":\"wing\",\"score\":0.103},{\"class\":\"chain saw, chainsaw\",\"score\":0.07},{\"class\":\"aircraft carrier, carrier, flattop, attack aircraft carrier\",\"score\":0.048}]}', b'{\"classPredictions\":[{\"class\":\"airliner\",\"score\":0.606},{\"class\":\"crane\",\"score\":0.11},{\"class\":\"wing\",\"score\":0.103},{\"class\":\"chain saw, chainsaw\",\"score\":0.07},{\"class\":\"aircraft carrier, carrier, flattop, attack aircraft carrier\",\"score\":0.048}]}', b'{\"classPredictions\":[{\"class\":\"airliner\",\"score\":0.606},{\"class\":\"crane\",\"score\":0.11},{\"class\":\"wing\",\"score\":0.103},{\"class\":\"chain saw, chainsaw\",\"score\":0.07},{\"class\":\"aircraft carrier, carrier, flattop, attack aircraft carrier\",\"score\":0.048}]}']\n"
     ]
    }
   ],
   "source": [
    "# test batch locally\n",
    "results = chassis_model.test_batch(sample_filepath)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish model to Modzy\n",
    "Need to provide model name, model version, Dockerhub credentials, and required Modzy info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting build job... Ok!\n"
     ]
    }
   ],
   "source": [
    "response = chassis_model.publish(model_name=\"Torch Imagenet GPU\",model_version=\"0.0.1\",\n",
    "                     registry_user=dockerhub_user,registry_pass=dockerhub_pass,\n",
    "                     modzy_sample_input_path=sample_filepath,\n",
    "                     modzy_api_key=modzy_api_key,gpu=True)\n",
    "\n",
    "job_id = response.get('job_id')\n",
    "final_status = chassis_client.block_until_complete(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run sample job\n",
    "Submit inference job to our newly-deploy model running on Modzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modzy import ApiClient\n",
    "\n",
    "client = ApiClient(base_url='https://integration.modzy.engineering/api', api_key=modzy_api_key)\n",
    "\n",
    "input_name = final_status['result']['inputs'][0]['name']\n",
    "model_id = final_status['result'].get(\"model\").get(\"modelId\")\n",
    "model_version = final_status['result'].get(\"version\")\n",
    "\n",
    "# submit 16 inputs\n",
    "sources = {\"input_{}\".format(i): {input_name: sample_filepath} for i in range(16)}\n",
    "inference_job = client.jobs.submit_file(model_id, model_version, sources)\n",
    "inference_job_result = client.results.block_until_complete(inference_job, timeout=None)\n",
    "print(inference_job_result[\"results\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95ab8d3bdd708a5b71676285742277315a30b0df1ed91c8905076616709c59d5"
  },
  "kernelspec": {
   "display_name": "chassis-demo",
   "language": "python",
   "name": "chassis-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
