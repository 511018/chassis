{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chassisml\n",
    "import pickle\n",
    "import cv2\n",
    "import torch\n",
    "import getpass\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter credentials\n",
    "Dockerhub creds and Modzy API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker hub username········\n",
      "docker hub password········\n",
      "modzy api key········\n"
     ]
    }
   ],
   "source": [
    "dockerhub_user = getpass.getpass('docker hub username')\n",
    "dockerhub_pass = getpass.getpass('docker hub password')\n",
    "modzy_api_key = getpass.getpass('modzy api key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare context dict\n",
    "Initialize anything here that should persist across inference runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "])       \n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "# This will be passed to Chassis:\n",
    "context = {\n",
    "    \"model\": model,\n",
    "    \"labels\": COCO_INSTANCE_CATEGORY_NAMES,\n",
    "    \"transform\": transform,\n",
    "    \"device\": device\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write process function\n",
    "\n",
    "* Must take bytes and context dict as input\n",
    "* Preprocess bytes, run inference, postprocess model output, return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(input_bytes,context):\n",
    "    \n",
    "    # preprocess\n",
    "    decoded = cv2.imdecode(np.frombuffer(input_bytes, np.uint8), -1)\n",
    "    img_t = context['transform'](decoded)\n",
    "    batch_t = torch.unsqueeze(img_t, 0).to(device)\n",
    "    \n",
    "    # run inference\n",
    "    predictions = context['model'](batch_t)[0]\n",
    "    num_detections = len(predictions[\"boxes\"])\n",
    "    \n",
    "    # postprocess\n",
    "    inference_result = {\n",
    "        \"detections\": [\n",
    "            {\n",
    "                \"xMin\": predictions[\"boxes\"][i].detach().cpu().numpy().tolist()[0],\n",
    "                \"xMax\": predictions[\"boxes\"][i].detach().cpu().numpy().tolist()[2],\n",
    "                \"yMin\": predictions[\"boxes\"][i].detach().cpu().numpy().tolist()[1],\n",
    "                \"yMax\": predictions[\"boxes\"][i].detach().cpu().numpy().tolist()[3],\n",
    "                \"class\": context[\"labels\"][predictions[\"labels\"][i].detach().cpu().item()],\n",
    "                \"classProbability\": predictions[\"scores\"][i].detach().cpu().item(),\n",
    "            } for i in range(num_detections)\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    structured_output = {\n",
    "        \"data\": {\n",
    "            \"result\": inference_result,\n",
    "            \"explanation\": None,\n",
    "            \"drift\": None,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return structured_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Chassis Client\n",
    "We'll use this to interact with the Chassis service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chassis_client = chassisml.ChassisClient(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and test Chassis model\n",
    "* Requires `context` dict containing all variables which should be loaded once and persist across inferences\n",
    "* Requires `process_fn` defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\chassis-demo\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"data\":{\"result\":{\"detections\":[{\"xMin\":112.44477844238281,\"xMax\":594.023681640625,\"yMin\":10.943532943725586,\"yMax\":201.69760131835938,\"class\":\"airplane\",\"classProbability\":0.9996569156646729}]},\"explanation\":null,\"drift\":null}}'\n"
     ]
    }
   ],
   "source": [
    "# create Chassis model\n",
    "chassis_model = chassis_client.create_model(context=context,process_fn=process)\n",
    "\n",
    "# test Chassis model (can pass filepath, bufferedreader, bytes, or text here):\n",
    "sample_filepath = './data/airplane.jpg'\n",
    "results = chassis_model.test(sample_filepath)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test job... Ok!\n",
      "{'model_output': 'b\\'{\"data\":{\"result\":{\"detections\":[{\"xMin\":112.44477844238281,\"xMax\":594.023681640625,\"yMin\":10.943532943725586,\"yMax\":201.69760131835938,\"class\":\"airplane\",\"classProbability\":0.9996569156646729}]},\"explanation\":null,\"drift\":null}}\\'\\n'}\n"
     ]
    }
   ],
   "source": [
    "# test environment and model within Chassis service, must pass filepath here:\n",
    "test_env_result = chassis_model.test_env(sample_filepath)\n",
    "print(test_env_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish model to Modzy\n",
    "Need to provide model name, model version, Dockerhub credentials, and required Modzy info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting build job... Ok!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BRADLE~1\\AppData\\Local\\Temp/ipykernel_23436/2289102955.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mjob_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job_id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mfinal_status\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchassis_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock_until_complete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\chassisml\\chassisml.py\u001b[0m in \u001b[0;36mblock_until_complete\u001b[1;34m(self, job_id, timeout, poll_interval)\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m             \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_job_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'status'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'succeeded'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'status'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'failed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mendby\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mendby\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpoll_interval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "response = chassis_model.publish(\n",
    "    model_name=\"PyTorch Faster R-CNN Object Detection\",\n",
    "    model_version=\"0.0.1\",\n",
    "    registry_user=dockerhub_user,\n",
    "    registry_pass=dockerhub_pass,\n",
    "    modzy_sample_input_path=sample_filepath,\n",
    "    modzy_api_key=modzy_api_key\n",
    ")\n",
    "\n",
    "job_id = response.get('job_id')\n",
    "final_status = chassis_client.block_until_complete(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chassis job failed \n",
      "\n",
      " {'result': None, 'status': {'active': 1, 'completion_time': None, 'conditions': None, 'failed': None, 'start_time': 'Fri, 07 Jan 2022 02:22:49 GMT', 'succeeded': None}}\n"
     ]
    }
   ],
   "source": [
    "if chassis_client.get_job_status(job_id)[\"result\"] is not None:\n",
    "    print(\"New model URL: {}\".format(chassis_client.get_job_status(job_id)[\"result\"][\"container_url\"]))\n",
    "else:\n",
    "    print(\"Chassis job failed \\n\\n {}\".format(chassis_client.get_job_status(job_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run sample job\n",
    "Submit inference job to our newly-deploy model running on Modzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ApiObject({\n",
      "  \"data\": {\n",
      "    \"drift\": null,\n",
      "    \"explanation\": null,\n",
      "    \"result\": {\n",
      "      \"detections\": [\n",
      "        {\n",
      "          \"class\": \"airplane\",\n",
      "          \"classProbability\": 0.9996569156646729,\n",
      "          \"xMax\": 594.023681640625,\n",
      "          \"xMin\": 112.44480895996094,\n",
      "          \"yMax\": 201.69760131835938,\n",
      "          \"yMin\": 10.943532943725586\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from modzy import ApiClient\n",
    "\n",
    "client = ApiClient(base_url='https://integration.modzy.engineering/api', api_key=modzy_api_key)\n",
    "\n",
    "input_name = \"input\"# final_status['result']['inputs'][0]['name']\n",
    "model_id = \"mbi6fv1hxk\" # final_status['result'].get(\"model\").get(\"modelId\")\n",
    "model_version = \"0.0.1\" # final_status['result'].get(\"version\")\n",
    "\n",
    "inference_job = client.jobs.submit_file(model_id, model_version, {input_name: sample_filepath})\n",
    "inference_job_result = client.results.block_until_complete(inference_job, timeout=None)\n",
    "inference_job_results_json = inference_job_result.get_first_outputs()['results.json']\n",
    "print(inference_job_results_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95ab8d3bdd708a5b71676285742277315a30b0df1ed91c8905076616709c59d5"
  },
  "kernelspec": {
   "display_name": "chassis-demo-1",
   "language": "python",
   "name": "chassis-demo-1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
